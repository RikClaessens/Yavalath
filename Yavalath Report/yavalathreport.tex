% !TEX root = yavalathreport.tex
%!%TEX program = xelatex
\documentclass[11pt]{article}

	\input{settings/settings.tex}

\begin{document}

\title{{\Huge Yavalath} \\ \vspace{0.5em}{\large August 2014 - Intelligent Search \& Games\\ Master Artificial Intelligence, Maastricht University}}	
\author{Rik Claessens}

\maketitle

\begin{abstract}
Yavalath is a board game created by a computer program called Ludi. This paper describes an $\alpha\beta$-implementation for the game of Yavalath. A number of enhancements over the vanilla $\alpha \beta$-framework and their impact on game playing performance is evaluated.
\end{abstract}

\section{The Game of Yavalath}
\label{-sec:thegameofyavalath}
Yavalath is played on board made up of a hexagonal grid of 61 cells. It is the first commercial board game that was generated by a computer program. This general game system is called Ludi and was created by Cameron Browne \cite{browne2011evolutionary}. The rules of Yavalath are defined in the \ac{GDL} as presented in Listing \ref{lst:yavalathgdl}. 

\listingspace
\begin{lstlisting}[caption={The Yavalath definition in GDL}]
(game Yavalath
	(players White Black)
	(board (tiling hex) (shape hex) (size 5))
	(pieces (Piece All (moves (move (pre (empty to))
		(action (push)))))) 
	(end
		(All win (in-a-row 4))
		(All lose (and (in-a-row 3) (not (in-a-row 4))))
	)
)
\end{lstlisting}
\label{lst:yavalathgdl}
\listingspace

As the game can be defined in just these few lines, the rules are very straightforward. The game is played with 2 players, White and Black, on a hexagonal shaped board of size 5 (Figure \ref{fig:emptyboard}). Allowed moves consist of placing a stone on one of the free cells remaining on the board. A player wins if he completes a line of four but loses if he completes a line of three before. The commonly used swap rule is also used in Yavalath in order to avoid a too strong opening move option for White. 

\input{figures/emptyboard.tex}

One of the key aspects of Yavalath is the forcing move. When a player has - in any direction - a line consisting of one stone of his color, one free cell and then another two stones of his color, he forces his opponent to play the move on the free field (or one of multiple fields with the same configuration). An example of a forced move is shown in Figure \ref{fig:forcedmoves}. By playing the move marked 1, White forces Black to play move 2 (forced moves are labeled in red), thereby forcing Black to create a line of three, which means that Black will lose. This mechanic will prove essential for the developed agent as by using forced moves it is possible to limit your opponents options and control where he is able to make his next move.

\input{figures/forcedmoves.tex}

Its simple set of rules and the unique winning condition is what Yavalath is most famous for and what made it one of the most popular board games on the website \url{www.boardgamegeek.com}. The game could also be played with three players where the only difference is that a player that makes a line of three leaves the game, after which the game is continued until a player wins by creating a line of four or by being the only remaining in the game. Furthermore, the active player is required to play any forced moves by the previous player. In this report however, we only consider the two-player variant of Yavalath.

\section{Evaluation Function}
\label{-sec:evaluationfunction}

Crucial for any AI player is a well-performing evaluation function. We discuss the Yavalath evaluation function according to seven principles as presented in \cite{Winands2004}. These seven principles include: \begin{enumerate*}\item threats, \item solid formations, \item mobility, \item blocking, \item centralisation, \item material advantage and \item initiative\end{enumerate*}.

\subsection{Win or Loss}
\label{-subsec:winorloss}
First of all, if a board is a win or loss for the player, the evaluation of the board is given by:
\begin{equation}\label{eq:winscore}
score = \twopartdef{\phantom{-}WIN\ SCORE - \#\ of\ moves\ made}{\mbox{the position is a WIN}}{-WIN\ SCORE + \#\ of\ moves\ made}{\mbox{the position is a LOSS.}}
\end{equation}

With this game over evaluation score, we take into account the depth at which a win or loss was found. Obviously, obtaining a win sooner and delaying a loss as long as possible is preferable, so we subtract or add the number of moves made to the $WIN\ SCORE$ and the negative $WIN\ SCORE$ respectively.

\subsection{Inapplicable evaluation function features}
\label{-subsec:inapplicableevaluationfunctionfeatures}
First we describe the features that are inapplicable for Yavalath and why that is the case.

\subsubsection{Mobility}
\label{-subsubsec:mobility}
As there are no restrictions where a player is able to move and pieces are not moved across the board, but instead placed at empty squares, mobility does not play a role in Yavalath.

\subsubsection{Material Advantage}
\label{-subsubsec:materialadvantage}
Another feature that is in inapplicable for Yavalath is material advantage. This is the case because pieces cannot be captured by other players. Therefore, the number of pieces on the board is equal to the number of moves made thus far and all players will have the same number of pieces on the board after each complete game round.

\subsection{Threats}
\label{-subsec:threats}
A returning aspect of Yavalath is forcing your opponent to make certain moves. In this way one is able to limit his opponents options. A formation that could lead to a forced move for the player can therefore be seen as a threat. This is the case when in any straight line of four fields, there are two pieces of the opponent's color and two free fields. The three threat formations are shown in Figure \ref{fig:threat}, which can appear in multiple directions on the board. If the player does not play on one of the free fields, but the opponent does, White is forced to make a move.

\input{figures/threat.tex}

A threat is evaluated as a penalty of $5$. This value was chosen to not let this feature to become overly strong, because it is not a direct distance to win indicator. This is the case because it is possible that being forced to move does not present any immediate danger for losing. It was observed that the developed AI player would start blocking off every existing threat, which lead him to ignore his own strong positions and a too high threat evaluation penalty would often result in a loss.

\subsection{Solid Formations}
\label{-subsec:solidformations}
There are a number of solid formations in the game of Yavalath. Forcing the opponent to make certain moves is a crucial aspect of Yavalath and it also place a strong role in determining strong formations. A number of these formations are described in \cite{browne2011evolutionary} and are shown in Figure \ref{fig:solidformations}. These triangles each form a basis on which White can force Black to play certain moves and, if Black fails to block the position in a proper way, will lead to a win for White.

\input{figures/solidformations.tex}

The strength of these triangle formations lies in the fact that they can be applied in two \emph{directions of play} and three \emph{rotations of play}. What we mean with this is that the first move can be played in two directions of each side of the triangle. If the opponent thus blocks of one side of the triangle, the AI player still has various other options to make a move.

In addition to the formations presented in \cite{browne2011evolutionary} (Figure \ref{fig:solidformations}), we would like to add several combinations of these triangles of size 2, 3 and 4. These formations, along with the winning move sequence are presented in Figure \ref{fig:additionalsolidformations}.

\input{figures/additionalsolidformations.tex}

These additional formations do not have the advantage that they can be played in any direction like the formations in Figure \ref{fig:solidformations}. However, it is clear that formations that pose a threat for the opponent and can be used to force him to move are crucial in Yavalath.

The formations are evaluated as presented in Table \ref{tab:evaluationsolidformations}.

\input{figures/solidformationsevaluation.tex}

\subsection{Centralisation}
\label{-subsec:centralisation}
Another part of the evaluation function for the game of Yavalath is centralisation. The intuition behind this feature is that playing near the center of the board gives the player more options to choose from, \ie more directions to play in. Therefore we give all fields a score, based on the distance to the edge of the board. These distances are shown in Figure \ref{fig:scores}. 

\input{figures/scores.tex}

The centralisation score is then defined as:

\begin{equation}
	centralisation\ score = distance \mydot distance\ score,
\end{equation}

where we set $distance\ score = 20$.

However, because of the swap rule, we remove the bonus for the central two hexagonal circles (all fields with distances of $4$ or $5$) for the first move if the AI player is White. This is to prevent the player from playing a move that will very likely be swapped during Black's first move anyway, thereby losing his first move advantage.

\subsection{Initiative}
\label{-subsec:initiative}
The last evaluation function principle proposed by \cite{Winands2004} is initiative. Obtaining the initiative in the game of Yavalath is useful for forcing moves by the opponent, thereby limiting his options and with that his ability to force moves for the AI player. Because of this the sooner, a move can be forced by the AI player, the better. Therefore, when a move is forced by the opponent, the player gets a penalty of $5$ per forced move, but the evaluation score is increased with $20$ per move forced by the player during his last turn.

\section{\texorpdfstring{$\boldsymbol{\alpha\beta}$}{alphabeta}-enhancements}
\label{-sec:alphabeta-enhancements}%fixed
In this section we describe a number of enhancements made to the general $\alpha\beta$-framework. These include \begin{enumerate*}\item move ordering, \item a transposition table, \item killer moves, \item null moves, \item quiescence search, \item the relative history heuristic and \item aspiration search.\end{enumerate*}
As a first remark, although the AI player will not participate in a tournament, it still makes use of iterative deepening in order to stay as close as possible to an AI player that could be used in a real game or tournament. Iterative deepening performs the same $\alpha\beta$-search for increasing depth, starting at depth $1$. The costs of the repeated search can be compensated by using a number of enhancements to increase the number of $\alpha\beta$-cutoffs when searching at increased depths.

\subsection{Transposition Table}
\label{-subsec:transpositiontable}
In games where it is possible to obtain the same board position after different move sequences, it is possible to use a transposition table to speed up the search. This speed-up is achieved by storing already evaluated positions, along with the obtained value, its flag (exact, upper bound or lower bound) and the depth at which the position was evaluated. Then, when the position appears again while traversing the tree, the previously obtained result can be used if the remaining search depth is equal or smaller for the current position.

For the transposition table, a set of $3\times 61$ random numbers is used to create a zobirst hash-value for a position. This hash is used to store and retrieve a transposition. When a collision occurs, the position which has been evaluated deeper, \ie the biggest subtree is maintained. The size of the transposition table is set to $2^{26}\approx 67$ million positions.

\subsection{Null Moves}
\label{-subsec:nullmoves}
The idea of null moves is that any position on which a player is able to forfeit a move and remains a strong position, will be an even stronger position when he would have made a move. In Yavalath, we do not allow null moves when a player is forced to make a move. Furthermore, we do not allow two consecutive null moves as this would allow the opponent in a lot of situations to create positions that leads to forced moves by the player. This does not help the search as it gives a overly pessimistic evaluation of the position under consideration. A value of $R=2$ is used for the reduced search depth after a null move has been made.

\subsection{Relative History Heuristic}
\label{-subsec:relativehistoryheuristic}
Instead of a static move ordering, the relative history heuristic can be used \cite{Herik}. The heuristic is a relative measure of the history score that counts the number of times a move has produced a cut-off and the butterfly score that counts the number of times a move did not result in a cut-off. The relative history heuristic defines the score of a move as:

\begin{equation}
	move\ score = \frac{hh\ score}{bf\ score},
\end{equation}

where the $hh\ score$ is the history heuristic score and $bf\ score$ is the butterfly score \cite{Winands2004}. As suggested in the same thesis, the $hh\ score$ and $bf\ score$ are both incremented by $1$ in case of a cut-off and no cut-off respectively. This move ordering is used after the killer move and transposition table move have been evaluated.

\subsection{Move ordering}
\label{-subsec:moveordering}
Before moves are evaluated at a certain depth, the allowed moves are sorted. The goal of this move ordering is to achieve an $\alpha\beta$-cutoff as soon as possible. The sooner a cutoff is achieved, the more the search is sped up. Several techniques suggest good moves to try first at a certain depth, killer moves, principal variation moves from previous searches and transposition tables. Generally, null moves are tried first if they are allowed. Then, as this gives us the most reliable information, the retrieved move from the transposition table is performed, then the principal variation of the last iteration and finally the killer moves are played. Then the relative history heuristic can sort the remaining moves based on the number of times they appeared in the search. However, a static move ordering is used if this feature is disabled. This static move ordering is shown in Figure \ref{fig:staticmoveordering}.

\input{figures/moveordering.tex}

Moves are considered in an outwards spiraling order, as playing near the center gives the player most opportunities to create strong positions.

\subsection{Aspiration Search}
\label{-subsec:aspirationsearch}
The vanilla Negamax algorithm, starts the search with $\alpha$ and $\beta$ values of $-\infty$ and $+\infty$ respectively. Aspiration search attempts to speed up the search by making a guess of what the true score of a position will be and limiting the search window accordingly. As the developed agent uses iterative deepening we can use the obtained score from the previous search as the initial guess for the next iteration. The search window is then set as $(V-\Delta, V+\Delta)$, where $V$ is the value of our initial guess and $\Delta$ is the search window size. $\Delta$ is the parameter that needs tuning and this is often done by trail and error. 

The procedure is then started with a standard Negamax search, except using this limited window. If the resulting score is inside this window, we have obtained the result with very likely less explored nodes than with the standard window of $(-\infty,+\infty)$. However, if the score is lower than the lower bound of the window, \ie $score \leq \alpha$, the aspiration search failed low and the search is repeated with window $(-\infty,score)$. In the opposite case, when the score exceeds the upper bound of the search window, \ie $score > \beta$, the aspiration search failed high and we need to redo the search using the window $(score, +\infty)$. A good value for $\Delta$ is investigated in the next section, where we discuss the experiments.

\section{Experiments}
\label{-sec:experiments}
In order to test the performance of the developed AI player, a number of experiments were performed. Every $\alpha\beta$- enhancement is switched on individually to test the increase in performance. To compare the results, a search depth maximum of $5$ is chosen.

The experiments were run a Macbook Pro (Early 2014) with a 2,4 GHz Intel Core i5 processor and 8GB of RAM. The results are averages over a set of fixed games against the standard Negamax player with no enhancements turned on. The average number of moves per fame is $11,9$.

\subsection{Results}
\label{-subsec:results}

A series of results is presented in Figures \ref{tab:minimaxab}, (a) through (h).

\input{figures/results.tex}

The first thing that became clear during the experiments is that in the majority of the games, the game was won by forcing the opponent to create a line of three. A line of four in Yavalath is practically only achievable by having a formation where one piece is placed in such a way that it forces the opponent to move, but the opponent has two options to choose from. We never observed that the AI player was not able to block this formation attempt before it became a threat.

During game play testing, it was observed that the play outs presented in Figure \ref{fig:solidformations} emerged naturally. Due to the strength and lack of blocking options of the triangle of size two, the AI player often tried to obtain this position.

One of the most notable observations made during the experiments is that occasionally, null moves caused an earlier win than the configuration without null moves. This is the reason for the lower number of nodes in Figure \ref{tab:minimaxab}.(c) for depths $1$ and $2$. The null move evaluation thus sometimes might be too optimistic, thereby cutting off parts of the trees that would have been evaluated otherwise. In some occasions this lead to the player opening up to a series of forced moves from his opponent and sometimes this even lead to a loss for the AI player.

We expect this to be caused by the nature of the game. Yavalath is a game where a player does not need to have an elaborate piece positioning to obtain a win. Generally, a win is obtained by a small number of pieces that form a solid formation with which the player is able to force a line of three by his opponent. Therefore, playing a null move might result in an overly optimistic value, when the search depth is reduced by $R=2$.

\subsection{Move Ordering Experiments}
\label{-subsec:moveorderingexperiments}
We observe a huge increase in performance when using move ordering. Killer moves (Figure \ref{tab:minimaxab}.(d)), static move ordering (Figure \ref{tab:minimaxab}.(e)), as well as the relative history heuristic (Figure \ref{tab:minimaxab}.(f)) show a big number of nodes reduction. It is clear that in the game of Yavalath, fields with freedom to play in several directions are crucial for good performance. Based on these results, we can conclude that fields near the center of the board give the player a big tactical advantage. 

\subsection{Aspiration Search Experiments}
\label{-subsec:aspirationsearchexperiments}
In aspiration search, $\Delta$ is the parameter that needs tuning. This parameter determines the size of the window in which the true value of the negamax search is expected. Generally, a bigger $\Delta$ means a bigger chance that the true value is inside the window and thus less search repeats due to a high or low fail. However, a large value for $\Delta$ also means less cut-offs during the search. So we want to choose $\Delta$ as small as possible without leading to too much failures as this means repeating the search. In Figure \ref{tab:aspirationtable} we present the results of varying values for $\Delta$.

\input{figures/aspiration.tex}

We observe the biggest reduction in number of nodes visited for $\Delta=10$.

\section{Conclusions}
\label{-sec:conclusions}
From the experiments it is clear that the developed $\alpha\beta$-enhancements have a positive effect on the performance of the AI player. The biggest performance increase is obtained by a good move ordering as it is clear from the results presented in the previous section that the moves that give freedom in multiple directions are - especially in the early game - the moves to consider first. The AI player hardly ever plays near the edge of the board.

Furthermore, as expected, transposition tables also result in a big increase in performance. This is expected because a game tree for the game of Yavalath contains many transpositions due to the nature of the game, where no stones are captured but remain on the board after they have been placed. Also, since there are no restrictions in where a player is allowed to move, a transposition appears often in the search tree.

The AI player with all enhancements turned on achieves a $75\%$ reduction of the number of visited nodes on depth $5$ and is able to search a full ply deeper within reasonable amount of time, even at the start of the game.

\section{Acknowledgments}
\label{-sec:acknowledgments}
For displaying the board an existing display engine was used, published on Github by user silverio (\url{https://github.com/silverio/samples}).

\clearpage
	\nocite{*}
	\printbibliography
	\Numbering{Roman}{1}

\end{document}